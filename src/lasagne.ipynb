{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.nonlinearities import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load.get_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_size = X_train.shape[1]\n",
    "out_size = y_train.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net1 = NeuralNet(\n",
    "    layers=[  # three layers: one hidden layer\n",
    "        ('input', layers.InputLayer),\n",
    "        ('hidden', layers.DenseLayer),\n",
    "#         ('dropout1', layers.DropoutLayer),\n",
    "        ('hidden2', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    # layer parameters:\n",
    "    input_shape=(None, in_size),\n",
    "\n",
    "    hidden_num_units=128,\n",
    "    hidden2_num_units=50,\n",
    "#     dropout1_p=0.1,\n",
    "    output_nonlinearity=softmax,  # output layer uses identity function\n",
    "    output_num_units=out_size,\n",
    "\n",
    "    # optimization method:\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.0001,\n",
    "#     update_momentum=0.1,\n",
    "\n",
    "    max_epochs=5000,  # we want to train this many epochs\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input             \t(None, 93)          \tproduces      93 outputs\n",
      "  hidden            \t(None, 128)         \tproduces     128 outputs\n",
      "  hidden2           \t(None, 50)          \tproduces      50 outputs\n",
      "  output            \t(None, 9)           \tproduces       9 outputs\n",
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------\n",
      "     1  |  \u001b[94m  1.961896\u001b[0m  |  \u001b[32m  1.575114\u001b[0m  |     1.245558  |     52.28%  |  0.2s\n",
      "     2  |  \u001b[94m  1.439009\u001b[0m  |  \u001b[32m  1.346552\u001b[0m  |     1.068662  |     61.35%  |  0.2s\n",
      "     3  |  \u001b[94m  1.268573\u001b[0m  |  \u001b[32m  1.217208\u001b[0m  |     1.042199  |     64.51%  |  0.2s\n",
      "     4  |  \u001b[94m  1.161824\u001b[0m  |  \u001b[32m  1.127379\u001b[0m  |     1.030553  |     66.62%  |  0.2s\n",
      "     5  |  \u001b[94m  1.085841\u001b[0m  |  \u001b[32m  1.061008\u001b[0m  |     1.023406  |     67.95%  |  0.2s\n",
      "     6  |  \u001b[94m  1.029195\u001b[0m  |  \u001b[32m  1.010440\u001b[0m  |     1.018561  |     69.00%  |  0.2s\n",
      "     7  |  \u001b[94m  0.985432\u001b[0m  |  \u001b[32m  0.970921\u001b[0m  |     1.014945  |     69.67%  |  0.2s\n",
      "     8  |  \u001b[94m  0.950716\u001b[0m  |  \u001b[32m  0.939309\u001b[0m  |     1.012144  |     70.07%  |  0.2s\n",
      "     9  |  \u001b[94m  0.922446\u001b[0m  |  \u001b[32m  0.913473\u001b[0m  |     1.009822  |     70.41%  |  0.2s\n",
      "    10  |  \u001b[94m  0.898985\u001b[0m  |  \u001b[32m  0.891954\u001b[0m  |     1.007882  |     70.70%  |  0.2s\n",
      "    11  |  \u001b[94m  0.879194\u001b[0m  |  \u001b[32m  0.873791\u001b[0m  |     1.006183  |     70.97%  |  0.2s\n",
      "    12  |  \u001b[94m  0.862204\u001b[0m  |  \u001b[32m  0.858224\u001b[0m  |     1.004638  |     71.33%  |  0.2s\n",
      "    13  |  \u001b[94m  0.847433\u001b[0m  |  \u001b[32m  0.844595\u001b[0m  |     1.003360  |     71.61%  |  0.2s\n",
      "    14  |  \u001b[94m  0.834408\u001b[0m  |  \u001b[32m  0.832623\u001b[0m  |     1.002145  |     71.86%  |  0.3s\n",
      "    15  |  \u001b[94m  0.822828\u001b[0m  |  \u001b[32m  0.821971\u001b[0m  |     1.001042  |     72.12%  |  0.2s\n",
      "    16  |  \u001b[94m  0.812423\u001b[0m  |  \u001b[32m  0.812434\u001b[0m  |     0.999986  |     72.37%  |  0.2s\n",
      "    17  |  \u001b[94m  0.802992\u001b[0m  |  \u001b[32m  0.803808\u001b[0m  |     0.998984  |     72.54%  |  0.2s\n",
      "    18  |  \u001b[94m  0.794402\u001b[0m  |  \u001b[32m  0.795971\u001b[0m  |     0.998028  |     72.63%  |  0.2s\n",
      "    19  |  \u001b[94m  0.786534\u001b[0m  |  \u001b[32m  0.788836\u001b[0m  |     0.997082  |     72.77%  |  0.2s\n",
      "    20  |  \u001b[94m  0.779285\u001b[0m  |  \u001b[32m  0.782282\u001b[0m  |     0.996169  |     72.90%  |  0.2s\n",
      "    21  |  \u001b[94m  0.772575\u001b[0m  |  \u001b[32m  0.776268\u001b[0m  |     0.995242  |     73.02%  |  0.2s\n",
      "    22  |  \u001b[94m  0.766341\u001b[0m  |  \u001b[32m  0.770726\u001b[0m  |     0.994311  |     73.13%  |  0.2s\n",
      "    23  |  \u001b[94m  0.760515\u001b[0m  |  \u001b[32m  0.765608\u001b[0m  |     0.993347  |     73.30%  |  0.2s\n",
      "    24  |  \u001b[94m  0.755043\u001b[0m  |  \u001b[32m  0.760858\u001b[0m  |     0.992357  |     73.36%  |  0.2s\n",
      "    25  |  \u001b[94m  0.749909\u001b[0m  |  \u001b[32m  0.756422\u001b[0m  |     0.991390  |     73.51%  |  0.2s\n",
      "    26  |  \u001b[94m  0.745060\u001b[0m  |  \u001b[32m  0.752252\u001b[0m  |     0.990440  |     73.57%  |  0.2s\n",
      "    27  |  \u001b[94m  0.740482\u001b[0m  |  \u001b[32m  0.748339\u001b[0m  |     0.989500  |     73.65%  |  0.2s\n",
      "    28  |  \u001b[94m  0.736146\u001b[0m  |  \u001b[32m  0.744632\u001b[0m  |     0.988603  |     73.70%  |  0.2s\n",
      "    29  |  \u001b[94m  0.732024\u001b[0m  |  \u001b[32m  0.741123\u001b[0m  |     0.987723  |     73.75%  |  0.2s\n",
      "    30  |  \u001b[94m  0.728095\u001b[0m  |  \u001b[32m  0.737795\u001b[0m  |     0.986853  |     73.84%  |  0.2s\n",
      "    31  |  \u001b[94m  0.724339\u001b[0m  |  \u001b[32m  0.734647\u001b[0m  |     0.985969  |     73.96%  |  0.2s\n",
      "    32  |  \u001b[94m  0.720747\u001b[0m  |  \u001b[32m  0.731624\u001b[0m  |     0.985133  |     74.08%  |  0.2s\n",
      "    33  |  \u001b[94m  0.717310\u001b[0m  |  \u001b[32m  0.728734\u001b[0m  |     0.984324  |     74.13%  |  0.2s\n",
      "    34  |  \u001b[94m  0.714022\u001b[0m  |  \u001b[32m  0.725995\u001b[0m  |     0.983509  |     74.24%  |  0.2s\n",
      "    35  |  \u001b[94m  0.710877\u001b[0m  |  \u001b[32m  0.723367\u001b[0m  |     0.982733  |     74.27%  |  0.2s\n",
      "    36  |  \u001b[94m  0.707848\u001b[0m  |  \u001b[32m  0.720849\u001b[0m  |     0.981964  |     74.36%  |  0.2s\n",
      "    37  |  \u001b[94m  0.704926\u001b[0m  |  \u001b[32m  0.718438\u001b[0m  |     0.981193  |     74.48%  |  0.2s\n",
      "    38  |  \u001b[94m  0.702110\u001b[0m  |  \u001b[32m  0.716126\u001b[0m  |     0.980428  |     74.56%  |  0.2s\n",
      "    39  |  \u001b[94m  0.699388\u001b[0m  |  \u001b[32m  0.713890\u001b[0m  |     0.979686  |     74.57%  |  0.2s\n",
      "    40  |  \u001b[94m  0.696756\u001b[0m  |  \u001b[32m  0.711745\u001b[0m  |     0.978940  |     74.60%  |  0.2s\n",
      "    41  |  \u001b[94m  0.694212\u001b[0m  |  \u001b[32m  0.709683\u001b[0m  |     0.978199  |     74.67%  |  0.2s\n",
      "    42  |  \u001b[94m  0.691753\u001b[0m  |  \u001b[32m  0.707684\u001b[0m  |     0.977488  |     74.68%  |  0.2s\n",
      "    43  |  \u001b[94m  0.689377\u001b[0m  |  \u001b[32m  0.705753\u001b[0m  |     0.976796  |     74.70%  |  0.2s\n",
      "    44  |  \u001b[94m  0.687076\u001b[0m  |  \u001b[32m  0.703873\u001b[0m  |     0.976137  |     74.79%  |  0.2s\n",
      "    45  |  \u001b[94m  0.684846\u001b[0m  |  \u001b[32m  0.702057\u001b[0m  |     0.975485  |     74.83%  |  0.2s\n",
      "    46  |  \u001b[94m  0.682677\u001b[0m  |  \u001b[32m  0.700300\u001b[0m  |     0.974834  |     74.91%  |  0.2s\n",
      "    47  |  \u001b[94m  0.680571\u001b[0m  |  \u001b[32m  0.698600\u001b[0m  |     0.974193  |     74.90%  |  0.2s\n",
      "    48  |  \u001b[94m  0.678519\u001b[0m  |  \u001b[32m  0.696956\u001b[0m  |     0.973547  |     74.95%  |  0.2s\n",
      "    49  |  \u001b[94m  0.676526\u001b[0m  |  \u001b[32m  0.695364\u001b[0m  |     0.972910  |     74.97%  |  0.2s\n",
      "    50  |  \u001b[94m  0.674578\u001b[0m  |  \u001b[32m  0.693809\u001b[0m  |     0.972282  |     74.98%  |  0.2s\n",
      "    51  |  \u001b[94m  0.672674\u001b[0m  |  \u001b[32m  0.692306\u001b[0m  |     0.971642  |     75.00%  |  0.2s\n",
      "    52  |  \u001b[94m  0.670814\u001b[0m  |  \u001b[32m  0.690841\u001b[0m  |     0.971011  |     75.02%  |  0.2s\n",
      "    53  |  \u001b[94m  0.668997\u001b[0m  |  \u001b[32m  0.689405\u001b[0m  |     0.970397  |     75.13%  |  0.3s\n",
      "    54  |  \u001b[94m  0.667220\u001b[0m  |  \u001b[32m  0.688018\u001b[0m  |     0.969771  |     75.13%  |  0.2s\n",
      "    55  |  \u001b[94m  0.665488\u001b[0m  |  \u001b[32m  0.686660\u001b[0m  |     0.969166  |     75.12%  |  0.2s\n",
      "    56  |  \u001b[94m  0.663798\u001b[0m  |  \u001b[32m  0.685335\u001b[0m  |     0.968574  |     75.16%  |  0.2s\n",
      "    57  |  \u001b[94m  0.662145\u001b[0m  |  \u001b[32m  0.684044\u001b[0m  |     0.967987  |     75.16%  |  0.2s\n",
      "    58  |  \u001b[94m  0.660533\u001b[0m  |  \u001b[32m  0.682792\u001b[0m  |     0.967400  |     75.18%  |  0.2s\n",
      "    59  |  \u001b[94m  0.658952\u001b[0m  |  \u001b[32m  0.681570\u001b[0m  |     0.966816  |     75.15%  |  0.2s\n",
      "    60  |  \u001b[94m  0.657405\u001b[0m  |  \u001b[32m  0.680371\u001b[0m  |     0.966244  |     75.22%  |  0.2s\n",
      "    61  |  \u001b[94m  0.655886\u001b[0m  |  \u001b[32m  0.679207\u001b[0m  |     0.965665  |     75.16%  |  0.2s\n",
      "    62  |  \u001b[94m  0.654397\u001b[0m  |  \u001b[32m  0.678075\u001b[0m  |     0.965080  |     75.21%  |  0.2s\n",
      "    63  |  \u001b[94m  0.652932\u001b[0m  |  \u001b[32m  0.676963\u001b[0m  |     0.964502  |     75.21%  |  0.2s\n",
      "    64  |  \u001b[94m  0.651492\u001b[0m  |  \u001b[32m  0.675876\u001b[0m  |     0.963923  |     75.21%  |  0.2s\n",
      "    65  |  \u001b[94m  0.650081\u001b[0m  |  \u001b[32m  0.674802\u001b[0m  |     0.963367  |     75.18%  |  0.2s\n",
      "    66  |  \u001b[94m  0.648698\u001b[0m  |  \u001b[32m  0.673750\u001b[0m  |     0.962817  |     75.26%  |  0.2s\n",
      "    67  |  \u001b[94m  0.647339\u001b[0m  |  \u001b[32m  0.672727\u001b[0m  |     0.962260  |     75.31%  |  0.2s\n",
      "    68  |  \u001b[94m  0.646006\u001b[0m  |  \u001b[32m  0.671725\u001b[0m  |     0.961711  |     75.33%  |  0.2s\n",
      "    69  |  \u001b[94m  0.644699\u001b[0m  |  \u001b[32m  0.670749\u001b[0m  |     0.961162  |     75.41%  |  0.2s\n",
      "    70  |  \u001b[94m  0.643413\u001b[0m  |  \u001b[32m  0.669797\u001b[0m  |     0.960609  |     75.43%  |  0.2s\n",
      "    71  |  \u001b[94m  0.642150\u001b[0m  |  \u001b[32m  0.668871\u001b[0m  |     0.960049  |     75.44%  |  0.2s\n",
      "    72  |  \u001b[94m  0.640906\u001b[0m  |  \u001b[32m  0.667957\u001b[0m  |     0.959503  |     75.43%  |  0.2s\n",
      "    73  |  \u001b[94m  0.639685\u001b[0m  |  \u001b[32m  0.667058\u001b[0m  |     0.958965  |     75.50%  |  0.2s\n",
      "    74  |  \u001b[94m  0.638484\u001b[0m  |  \u001b[32m  0.666175\u001b[0m  |     0.958432  |     75.57%  |  0.2s\n",
      "    75  |  \u001b[94m  0.637307\u001b[0m  |  \u001b[32m  0.665312\u001b[0m  |     0.957907  |     75.62%  |  0.2s\n",
      "    76  |  \u001b[94m  0.636152\u001b[0m  |  \u001b[32m  0.664462\u001b[0m  |     0.957393  |     75.63%  |  0.2s\n",
      "    77  |  \u001b[94m  0.635013\u001b[0m  |  \u001b[32m  0.663626\u001b[0m  |     0.956884  |     75.63%  |  0.2s\n",
      "    78  |  \u001b[94m  0.633888\u001b[0m  |  \u001b[32m  0.662804\u001b[0m  |     0.956373  |     75.67%  |  0.2s\n",
      "    79  |  \u001b[94m  0.632781\u001b[0m  |  \u001b[32m  0.662005\u001b[0m  |     0.955855  |     75.73%  |  0.2s\n",
      "    80  |  \u001b[94m  0.631696\u001b[0m  |  \u001b[32m  0.661208\u001b[0m  |     0.955366  |     75.71%  |  0.3s\n",
      "    81  |  \u001b[94m  0.630626\u001b[0m  |  \u001b[32m  0.660433\u001b[0m  |     0.954868  |     75.73%  |  0.2s\n",
      "    82  |  \u001b[94m  0.629573\u001b[0m  |  \u001b[32m  0.659669\u001b[0m  |     0.954377  |     75.76%  |  0.2s\n",
      "    83  |  \u001b[94m  0.628539\u001b[0m  |  \u001b[32m  0.658923\u001b[0m  |     0.953888  |     75.76%  |  0.2s\n",
      "    84  |  \u001b[94m  0.627520\u001b[0m  |  \u001b[32m  0.658198\u001b[0m  |     0.953390  |     75.78%  |  0.2s\n",
      "    85  |  \u001b[94m  0.626515\u001b[0m  |  \u001b[32m  0.657482\u001b[0m  |     0.952900  |     75.81%  |  0.2s\n",
      "    86  |  \u001b[94m  0.625523\u001b[0m  |  \u001b[32m  0.656783\u001b[0m  |     0.952405  |     75.84%  |  0.3s\n",
      "    87  |  \u001b[94m  0.624547\u001b[0m  |  \u001b[32m  0.656093\u001b[0m  |     0.951918  |     75.86%  |  0.2s\n",
      "    88  |  \u001b[94m  0.623585\u001b[0m  |  \u001b[32m  0.655415\u001b[0m  |     0.951435  |     75.86%  |  0.2s\n",
      "    89  |  \u001b[94m  0.622635\u001b[0m  |  \u001b[32m  0.654748\u001b[0m  |     0.950953  |     75.88%  |  0.2s\n",
      "    90  |  \u001b[94m  0.621699\u001b[0m  |  \u001b[32m  0.654091\u001b[0m  |     0.950478  |     75.87%  |  0.2s\n",
      "    91  |  \u001b[94m  0.620773\u001b[0m  |  \u001b[32m  0.653440\u001b[0m  |     0.950008  |     75.90%  |  0.2s\n",
      "    92  |  \u001b[94m  0.619862\u001b[0m  |  \u001b[32m  0.652799\u001b[0m  |     0.949545  |     75.94%  |  0.2s\n",
      "    93  |  \u001b[94m  0.618959\u001b[0m  |  \u001b[32m  0.652178\u001b[0m  |     0.949064  |     75.96%  |  0.2s\n",
      "    94  |  \u001b[94m  0.618067\u001b[0m  |  \u001b[32m  0.651563\u001b[0m  |     0.948591  |     75.95%  |  0.2s\n",
      "    95  |  \u001b[94m  0.617188\u001b[0m  |  \u001b[32m  0.650963\u001b[0m  |     0.948116  |     75.96%  |  0.2s\n",
      "    96  |  \u001b[94m  0.616316\u001b[0m  |  \u001b[32m  0.650364\u001b[0m  |     0.947647  |     75.98%  |  0.2s\n",
      "    97  |  \u001b[94m  0.615456\u001b[0m  |  \u001b[32m  0.649774\u001b[0m  |     0.947184  |     76.01%  |  0.2s\n",
      "    98  |  \u001b[94m  0.614604\u001b[0m  |  \u001b[32m  0.649194\u001b[0m  |     0.946719  |     75.99%  |  0.2s\n",
      "    99  |  \u001b[94m  0.613761\u001b[0m  |  \u001b[32m  0.648631\u001b[0m  |     0.946241  |     76.04%  |  0.2s\n",
      "   100  |  \u001b[94m  0.612930\u001b[0m  |  \u001b[32m  0.648071\u001b[0m  |     0.945777  |     76.10%  |  0.2s\n",
      "   101  |  \u001b[94m  0.612110\u001b[0m  |  \u001b[32m  0.647511\u001b[0m  |     0.945328  |     76.11%  |  0.2s\n",
      "   102  |  \u001b[94m  0.611295\u001b[0m  |  \u001b[32m  0.646971\u001b[0m  |     0.944858  |     76.14%  |  0.2s\n",
      "   103  |  \u001b[94m  0.610494\u001b[0m  |  \u001b[32m  0.646433\u001b[0m  |     0.944404  |     76.17%  |  0.2s\n",
      "   104  |  \u001b[94m  0.609700\u001b[0m  |  \u001b[32m  0.645911\u001b[0m  |     0.943937  |     76.14%  |  0.2s\n",
      "   105  |  \u001b[94m  0.608914\u001b[0m  |  \u001b[32m  0.645396\u001b[0m  |     0.943473  |     76.20%  |  0.2s\n",
      "   106  |  \u001b[94m  0.608138\u001b[0m  |  \u001b[32m  0.644882\u001b[0m  |     0.943022  |     76.22%  |  0.2s\n",
      "   107  |  \u001b[94m  0.607366\u001b[0m  |  \u001b[32m  0.644374\u001b[0m  |     0.942566  |     76.23%  |  0.2s\n",
      "   108  |  \u001b[94m  0.606599\u001b[0m  |  \u001b[32m  0.643875\u001b[0m  |     0.942107  |     76.20%  |  0.2s\n",
      "   109  |  \u001b[94m  0.605841\u001b[0m  |  \u001b[32m  0.643374\u001b[0m  |     0.941662  |     76.18%  |  0.2s\n",
      "   110  |  \u001b[94m  0.605088\u001b[0m  |  \u001b[32m  0.642893\u001b[0m  |     0.941195  |     76.22%  |  0.2s\n",
      "   111  |  \u001b[94m  0.604342\u001b[0m  |  \u001b[32m  0.642411\u001b[0m  |     0.940741  |     76.24%  |  0.2s\n",
      "   112  |  \u001b[94m  0.603603\u001b[0m  |  \u001b[32m  0.641934\u001b[0m  |     0.940288  |     76.28%  |  0.2s\n",
      "   113  |  \u001b[94m  0.602872\u001b[0m  |  \u001b[32m  0.641474\u001b[0m  |     0.939824  |     76.32%  |  0.2s\n",
      "   114  |  \u001b[94m  0.602149\u001b[0m  |  \u001b[32m  0.641012\u001b[0m  |     0.939372  |     76.34%  |  0.2s\n",
      "   115  |  \u001b[94m  0.601430\u001b[0m  |  \u001b[32m  0.640553\u001b[0m  |     0.938923  |     76.32%  |  0.2s\n",
      "   116  |  \u001b[94m  0.600719\u001b[0m  |  \u001b[32m  0.640096\u001b[0m  |     0.938483  |     76.28%  |  0.2s\n",
      "   117  |  \u001b[94m  0.600014\u001b[0m  |  \u001b[32m  0.639642\u001b[0m  |     0.938046  |     76.32%  |  0.2s\n",
      "   118  |  \u001b[94m  0.599313\u001b[0m  |  \u001b[32m  0.639191\u001b[0m  |     0.937611  |     76.32%  |  0.2s\n",
      "   119  |  \u001b[94m  0.598619\u001b[0m  |  \u001b[32m  0.638766\u001b[0m  |     0.937149  |     76.36%  |  0.2s\n",
      "   120  |  \u001b[94m  0.597933\u001b[0m  |  \u001b[32m  0.638329\u001b[0m  |     0.936716  |     76.36%  |  0.2s\n",
      "   121  |  \u001b[94m  0.597255\u001b[0m  |  \u001b[32m  0.637902\u001b[0m  |     0.936280  |     76.38%  |  0.2s\n",
      "   122  |  \u001b[94m  0.596581\u001b[0m  |  \u001b[32m  0.637482\u001b[0m  |     0.935840  |     76.42%  |  0.2s\n",
      "   123  |  \u001b[94m  0.595918\u001b[0m  |  \u001b[32m  0.637059\u001b[0m  |     0.935420  |     76.44%  |  0.2s\n",
      "   124  |  \u001b[94m  0.595255\u001b[0m  |  \u001b[32m  0.636648\u001b[0m  |     0.934983  |     76.43%  |  0.2s\n",
      "   125  |  \u001b[94m  0.594605\u001b[0m  |  \u001b[32m  0.636237\u001b[0m  |     0.934565  |     76.44%  |  0.2s\n",
      "   126  |  \u001b[94m  0.593954\u001b[0m  |  \u001b[32m  0.635826\u001b[0m  |     0.934146  |     76.44%  |  0.3s\n",
      "   127  |  \u001b[94m  0.593312\u001b[0m  |  \u001b[32m  0.635421\u001b[0m  |     0.933730  |     76.43%  |  0.2s\n",
      "   128  |  \u001b[94m  0.592675\u001b[0m  |  \u001b[32m  0.635022\u001b[0m  |     0.933314  |     76.48%  |  0.2s\n",
      "   129  |  \u001b[94m  0.592047\u001b[0m  |  \u001b[32m  0.634625\u001b[0m  |     0.932908  |     76.47%  |  0.2s\n",
      "   130  |  \u001b[94m  0.591422\u001b[0m  |  \u001b[32m  0.634226\u001b[0m  |     0.932510  |     76.47%  |  0.2s\n",
      "   131  |  \u001b[94m  0.590801\u001b[0m  |  \u001b[32m  0.633844\u001b[0m  |     0.932092  |     76.49%  |  0.2s\n",
      "   132  |  \u001b[94m  0.590184\u001b[0m  |  \u001b[32m  0.633460\u001b[0m  |     0.931682  |     76.48%  |  0.2s\n",
      "   133  |  \u001b[94m  0.589570\u001b[0m  |  \u001b[32m  0.633085\u001b[0m  |     0.931265  |     76.52%  |  0.2s\n",
      "   134  |  \u001b[94m  0.588961\u001b[0m  |  \u001b[32m  0.632712\u001b[0m  |     0.930851  |     76.55%  |  0.2s\n",
      "   135  |  \u001b[94m  0.588360\u001b[0m  |  \u001b[32m  0.632324\u001b[0m  |     0.930472  |     76.56%  |  0.2s\n",
      "   136  |  \u001b[94m  0.587761\u001b[0m  |  \u001b[32m  0.631957\u001b[0m  |     0.930066  |     76.58%  |  0.2s\n",
      "   137  |  \u001b[94m  0.587167\u001b[0m  |  \u001b[32m  0.631585\u001b[0m  |     0.929671  |     76.53%  |  0.2s\n",
      "   138  |  \u001b[94m  0.586577\u001b[0m  |  \u001b[32m  0.631220\u001b[0m  |     0.929275  |     76.59%  |  0.2s\n",
      "   139  |  \u001b[94m  0.585992\u001b[0m  |  \u001b[32m  0.630854\u001b[0m  |     0.928888  |     76.59%  |  0.2s\n",
      "   140  |  \u001b[94m  0.585411\u001b[0m  |  \u001b[32m  0.630499\u001b[0m  |     0.928489  |     76.59%  |  0.2s\n",
      "   141  |  \u001b[94m  0.584835\u001b[0m  |  \u001b[32m  0.630134\u001b[0m  |     0.928112  |     76.62%  |  0.2s\n",
      "   142  |  \u001b[94m  0.584263\u001b[0m  |  \u001b[32m  0.629785\u001b[0m  |     0.927719  |     76.62%  |  0.2s\n",
      "   143  |  \u001b[94m  0.583694\u001b[0m  |  \u001b[32m  0.629442\u001b[0m  |     0.927319  |     76.62%  |  0.2s\n",
      "   144  |  \u001b[94m  0.583130\u001b[0m  |  \u001b[32m  0.629099\u001b[0m  |     0.926930  |     76.62%  |  0.2s\n",
      "   145  |  \u001b[94m  0.582572\u001b[0m  |  \u001b[32m  0.628759\u001b[0m  |     0.926543  |     76.64%  |  0.2s\n",
      "   146  |  \u001b[94m  0.582019\u001b[0m  |  \u001b[32m  0.628422\u001b[0m  |     0.926159  |     76.66%  |  0.2s\n",
      "   147  |  \u001b[94m  0.581468\u001b[0m  |  \u001b[32m  0.628088\u001b[0m  |     0.925775  |     76.67%  |  0.2s\n",
      "   148  |  \u001b[94m  0.580921\u001b[0m  |  \u001b[32m  0.627755\u001b[0m  |     0.925394  |     76.67%  |  0.2s\n",
      "   149  |  \u001b[94m  0.580379\u001b[0m  |  \u001b[32m  0.627422\u001b[0m  |     0.925021  |     76.67%  |  0.2s\n",
      "   150  |  \u001b[94m  0.579841\u001b[0m  |  \u001b[32m  0.627091\u001b[0m  |     0.924651  |     76.72%  |  0.2s\n",
      "   151  |  \u001b[94m  0.579306\u001b[0m  |  \u001b[32m  0.626766\u001b[0m  |     0.924278  |     76.72%  |  0.2s\n",
      "   152  |  \u001b[94m  0.578773\u001b[0m  |  \u001b[32m  0.626444\u001b[0m  |     0.923902  |     76.74%  |  0.2s\n",
      "   153  |  \u001b[94m  0.578244\u001b[0m  |  \u001b[32m  0.626131\u001b[0m  |     0.923519  |     76.78%  |  0.2s\n",
      "   154  |  \u001b[94m  0.577721\u001b[0m  |  \u001b[32m  0.625814\u001b[0m  |     0.923151  |     76.73%  |  0.2s\n",
      "   155  |  \u001b[94m  0.577205\u001b[0m  |  \u001b[32m  0.625503\u001b[0m  |     0.922785  |     76.74%  |  0.2s\n",
      "   156  |  \u001b[94m  0.576688\u001b[0m  |  \u001b[32m  0.625201\u001b[0m  |     0.922404  |     76.72%  |  0.2s\n",
      "   157  |  \u001b[94m  0.576179\u001b[0m  |  \u001b[32m  0.624891\u001b[0m  |     0.922048  |     76.73%  |  0.2s\n",
      "   158  |  \u001b[94m  0.575667\u001b[0m  |  \u001b[32m  0.624591\u001b[0m  |     0.921669  |     76.72%  |  0.2s\n",
      "   159  |  \u001b[94m  0.575162\u001b[0m  |  \u001b[32m  0.624284\u001b[0m  |     0.921315  |     76.72%  |  0.2s\n",
      "   160  |  \u001b[94m  0.574660\u001b[0m  |  \u001b[32m  0.623985\u001b[0m  |     0.920952  |     76.72%  |  0.2s\n",
      "   161  |  \u001b[94m  0.574164\u001b[0m  |  \u001b[32m  0.623683\u001b[0m  |     0.920602  |     76.72%  |  0.2s\n",
      "   162  |  \u001b[94m  0.573674\u001b[0m  |  \u001b[32m  0.623389\u001b[0m  |     0.920251  |     76.74%  |  0.2s\n",
      "   163  |  \u001b[94m  0.573186\u001b[0m  |  \u001b[32m  0.623096\u001b[0m  |     0.919900  |     76.73%  |  0.2s\n",
      "   164  |  \u001b[94m  0.572701\u001b[0m  |  \u001b[32m  0.622804\u001b[0m  |     0.919551  |     76.74%  |  0.2s\n",
      "   165  |  \u001b[94m  0.572220\u001b[0m  |  \u001b[32m  0.622521\u001b[0m  |     0.919197  |     76.77%  |  0.2s\n",
      "   166  |  \u001b[94m  0.571739\u001b[0m  |  \u001b[32m  0.622232\u001b[0m  |     0.918852  |     76.77%  |  0.2s\n",
      "   167  |  \u001b[94m  0.571266\u001b[0m  |  \u001b[32m  0.621944\u001b[0m  |     0.918517  |     76.77%  |  0.2s\n",
      "   168  |  \u001b[94m  0.570793\u001b[0m  |  \u001b[32m  0.621682\u001b[0m  |     0.918142  |     76.79%  |  0.2s\n",
      "   169  |  \u001b[94m  0.570325\u001b[0m  |  \u001b[32m  0.621407\u001b[0m  |     0.917796  |     76.83%  |  0.2s"
     ]
    }
   ],
   "source": [
    "net1.fit(X_train, y_train.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = net1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 5, ..., 5, 2, 7])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76253672869735556"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = load.get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------\n",
      "     1  |  \u001b[94m  0.602079\u001b[0m  |  \u001b[32m  1.004333\u001b[0m  |     0.599482  |     63.74%  |  0.2s\n",
      "     2  |    0.678213  |    1.031214  |     0.657684  |     63.44%  |  0.2s\n",
      "     3  |    0.684386  |    1.021748  |     0.669819  |     63.92%  |  0.2s\n",
      "     4  |    0.685230  |    1.010943  |     0.677813  |     64.33%  |  0.2s\n",
      "     5  |    0.685394  |  \u001b[32m  1.000013\u001b[0m  |     0.685385  |     64.60%  |  0.2s\n",
      "     6  |    0.685286  |  \u001b[32m  0.989378\u001b[0m  |     0.692644  |     64.72%  |  0.2s\n",
      "     7  |    0.685040  |  \u001b[32m  0.979146\u001b[0m  |     0.699630  |     64.98%  |  0.2s\n",
      "     8  |    0.684755  |  \u001b[32m  0.969457\u001b[0m  |     0.706329  |     65.25%  |  0.2s\n",
      "     9  |    0.684449  |  \u001b[32m  0.960089\u001b[0m  |     0.712901  |     65.51%  |  0.2s\n",
      "    10  |    0.684116  |  \u001b[32m  0.951089\u001b[0m  |     0.719297  |     65.79%  |  0.2s\n",
      "    11  |    0.683717  |  \u001b[32m  0.942497\u001b[0m  |     0.725432  |     66.09%  |  0.2s\n",
      "    12  |    0.683368  |  \u001b[32m  0.934338\u001b[0m  |     0.731392  |     66.32%  |  0.2s\n",
      "    13  |    0.683013  |  \u001b[32m  0.926522\u001b[0m  |     0.737179  |     66.58%  |  0.2s\n",
      "    14  |    0.682647  |  \u001b[32m  0.919057\u001b[0m  |     0.742768  |     66.81%  |  0.2s\n",
      "    15  |    0.682308  |  \u001b[32m  0.911908\u001b[0m  |     0.748219  |     66.99%  |  0.2s\n",
      "    16  |    0.681967  |  \u001b[32m  0.905045\u001b[0m  |     0.753517  |     67.15%  |  0.2s\n",
      "    17  |    0.681637  |  \u001b[32m  0.898260\u001b[0m  |     0.758842  |     67.35%  |  0.2s\n",
      "    18  |    0.681293  |  \u001b[32m  0.891896\u001b[0m  |     0.763870  |     67.53%  |  0.2s\n",
      "    19  |    0.680991  |  \u001b[32m  0.885717\u001b[0m  |     0.768859  |     67.70%  |  0.2s\n",
      "    20  |    0.680662  |  \u001b[32m  0.879828\u001b[0m  |     0.773631  |     67.92%  |  0.2s\n",
      "    21  |    0.680386  |  \u001b[32m  0.874117\u001b[0m  |     0.778370  |     68.13%  |  0.2s\n",
      "    22  |    0.680051  |  \u001b[32m  0.868610\u001b[0m  |     0.782918  |     68.25%  |  0.2s\n",
      "    23  |    0.679750  |  \u001b[32m  0.863356\u001b[0m  |     0.787335  |     68.38%  |  0.2s\n",
      "    24  |    0.679410  |  \u001b[32m  0.858284\u001b[0m  |     0.791592  |     68.47%  |  0.2s\n",
      "    25  |    0.679074  |  \u001b[32m  0.853380\u001b[0m  |     0.795746  |     68.61%  |  0.2s\n",
      "    26  |    0.678713  |  \u001b[32m  0.848688\u001b[0m  |     0.799720  |     68.71%  |  0.2s\n",
      "    27  |    0.678373  |  \u001b[32m  0.844160\u001b[0m  |     0.803607  |     68.79%  |  0.2s\n",
      "    28  |    0.678019  |  \u001b[32m  0.839797\u001b[0m  |     0.807361  |     68.91%  |  0.2s\n",
      "    29  |    0.677678  |  \u001b[32m  0.835612\u001b[0m  |     0.810996  |     69.04%  |  0.2s\n",
      "    30  |    0.677321  |  \u001b[32m  0.831524\u001b[0m  |     0.814555  |     69.15%  |  0.2s\n",
      "    31  |    0.676967  |  \u001b[32m  0.827543\u001b[0m  |     0.818044  |     69.29%  |  0.2s\n",
      "    32  |    0.676594  |  \u001b[32m  0.823677\u001b[0m  |     0.821431  |     69.42%  |  0.2s\n",
      "    33  |    0.676242  |  \u001b[32m  0.819911\u001b[0m  |     0.824775  |     69.55%  |  0.2s\n",
      "    34  |    0.675835  |  \u001b[32m  0.816279\u001b[0m  |     0.827947  |     69.66%  |  0.2s\n",
      "    35  |    0.675474  |  \u001b[32m  0.812732\u001b[0m  |     0.831115  |     69.75%  |  0.2s\n",
      "    36  |    0.675088  |  \u001b[32m  0.809270\u001b[0m  |     0.834194  |     69.92%  |  0.2s\n",
      "    37  |    0.674680  |  \u001b[32m  0.806019\u001b[0m  |     0.837052  |     69.98%  |  0.2s\n",
      "    38  |    0.674301  |  \u001b[32m  0.802752\u001b[0m  |     0.839987  |     70.06%  |  0.2s\n",
      "    39  |    0.673891  |  \u001b[32m  0.799614\u001b[0m  |     0.842771  |     70.17%  |  0.2s\n",
      "    40  |    0.673459  |  \u001b[32m  0.796580\u001b[0m  |     0.845438  |     70.22%  |  0.2s\n",
      "    41  |    0.673044  |  \u001b[32m  0.793551\u001b[0m  |     0.848142  |     70.33%  |  0.2s\n",
      "    42  |    0.672595  |  \u001b[32m  0.790635\u001b[0m  |     0.850702  |     70.44%  |  0.2s\n",
      "    43  |    0.672163  |  \u001b[32m  0.787813\u001b[0m  |     0.853201  |     70.54%  |  0.2s\n",
      "    44  |    0.671722  |  \u001b[32m  0.785025\u001b[0m  |     0.855670  |     70.69%  |  0.2s\n",
      "    45  |    0.671257  |  \u001b[32m  0.782406\u001b[0m  |     0.857940  |     70.74%  |  0.2s\n",
      "    46  |    0.670836  |  \u001b[32m  0.779809\u001b[0m  |     0.860257  |     70.76%  |  0.2s\n",
      "    47  |    0.670378  |  \u001b[32m  0.777332\u001b[0m  |     0.862409  |     70.83%  |  0.2s\n",
      "    48  |    0.669926  |  \u001b[32m  0.774903\u001b[0m  |     0.864529  |     70.86%  |  0.2s\n",
      "    49  |    0.669478  |  \u001b[32m  0.772567\u001b[0m  |     0.866563  |     70.95%  |  0.2s\n",
      "    50  |    0.669015  |  \u001b[32m  0.770273\u001b[0m  |     0.868542  |     70.99%  |  0.2s\n",
      "    51  |    0.668571  |  \u001b[32m  0.767988\u001b[0m  |     0.870550  |     71.15%  |  0.2s\n",
      "    52  |    0.668106  |  \u001b[32m  0.765811\u001b[0m  |     0.872416  |     71.20%  |  0.2s\n",
      "    53  |    0.667645  |  \u001b[32m  0.763676\u001b[0m  |     0.874252  |     71.28%  |  0.2s\n",
      "    54  |    0.667190  |  \u001b[32m  0.761615\u001b[0m  |     0.876020  |     71.36%  |  0.2s\n",
      "    55  |    0.666723  |  \u001b[32m  0.759619\u001b[0m  |     0.877708  |     71.45%  |  0.2s\n",
      "    56  |    0.666263  |  \u001b[32m  0.757667\u001b[0m  |     0.879362  |     71.49%  |  0.2s\n",
      "    57  |    0.665798  |  \u001b[32m  0.755766\u001b[0m  |     0.880958  |     71.56%  |  0.2s\n",
      "    58  |    0.665330  |  \u001b[32m  0.753909\u001b[0m  |     0.882507  |     71.62%  |  0.2s\n",
      "    59  |    0.664850  |  \u001b[32m  0.752123\u001b[0m  |     0.883964  |     71.61%  |  0.2s\n",
      "    60  |    0.664379  |  \u001b[32m  0.750341\u001b[0m  |     0.885436  |     71.65%  |  0.2s\n",
      "    61  |    0.663909  |  \u001b[32m  0.748575\u001b[0m  |     0.886898  |     71.68%  |  0.2s\n",
      "    62  |    0.663431  |  \u001b[32m  0.746844\u001b[0m  |     0.888312  |     71.70%  |  0.2s\n",
      "    63  |    0.662949  |  \u001b[32m  0.745160\u001b[0m  |     0.889674  |     71.74%  |  0.2s\n",
      "    64  |    0.662464  |  \u001b[32m  0.743513\u001b[0m  |     0.890992  |     71.78%  |  0.2s\n",
      "    65  |    0.661980  |  \u001b[32m  0.741940\u001b[0m  |     0.892229  |     71.80%  |  0.2s\n",
      "    66  |    0.661502  |  \u001b[32m  0.740382\u001b[0m  |     0.893461  |     71.85%  |  0.2s\n",
      "    67  |    0.661022  |  \u001b[32m  0.738915\u001b[0m  |     0.894584  |     71.87%  |  0.2s\n",
      "    68  |    0.660546  |  \u001b[32m  0.737470\u001b[0m  |     0.895692  |     71.92%  |  0.2s\n",
      "    69  |    0.660080  |  \u001b[32m  0.735995\u001b[0m  |     0.896854  |     72.05%  |  0.2s\n",
      "    70  |    0.659611  |  \u001b[32m  0.734561\u001b[0m  |     0.897966  |     72.11%  |  0.2s\n",
      "    71  |    0.659136  |  \u001b[32m  0.733179\u001b[0m  |     0.899011  |     72.11%  |  0.2s\n",
      "    72  |    0.658678  |  \u001b[32m  0.731823\u001b[0m  |     0.900051  |     72.19%  |  0.2s\n",
      "    73  |    0.658208  |  \u001b[32m  0.730496\u001b[0m  |     0.901043  |     72.18%  |  0.2s\n",
      "    74  |    0.657741  |  \u001b[32m  0.729180\u001b[0m  |     0.902029  |     72.23%  |  0.2s\n",
      "    75  |    0.657257  |  \u001b[32m  0.727920\u001b[0m  |     0.902924  |     72.28%  |  0.2s\n",
      "    76  |    0.656788  |  \u001b[32m  0.726705\u001b[0m  |     0.903789  |     72.31%  |  0.2s\n",
      "    77  |    0.656333  |  \u001b[32m  0.725478\u001b[0m  |     0.904690  |     72.32%  |  0.2s\n",
      "    78  |    0.655866  |  \u001b[32m  0.724280\u001b[0m  |     0.905542  |     72.35%  |  0.2s\n",
      "    79  |    0.655402  |  \u001b[32m  0.723068\u001b[0m  |     0.906418  |     72.41%  |  0.2s\n",
      "    80  |    0.654942  |  \u001b[32m  0.721887\u001b[0m  |     0.907263  |     72.44%  |  0.2s\n",
      "    81  |    0.654473  |  \u001b[32m  0.720733\u001b[0m  |     0.908065  |     72.51%  |  0.2s\n",
      "    82  |    0.654029  |  \u001b[32m  0.719576\u001b[0m  |     0.908908  |     72.52%  |  0.2s\n",
      "    83  |    0.653565  |  \u001b[32m  0.718459\u001b[0m  |     0.909676  |     72.60%  |  0.2s\n",
      "    84  |    0.653104  |  \u001b[32m  0.717349\u001b[0m  |     0.910441  |     72.63%  |  0.2s\n",
      "    85  |    0.652636  |  \u001b[32m  0.716281\u001b[0m  |     0.911146  |     72.65%  |  0.2s\n",
      "    86  |    0.652188  |  \u001b[32m  0.715201\u001b[0m  |     0.911894  |     72.66%  |  0.2s\n",
      "    87  |    0.651737  |  \u001b[32m  0.714149\u001b[0m  |     0.912607  |     72.72%  |  0.2s\n",
      "    88  |    0.651282  |  \u001b[32m  0.713141\u001b[0m  |     0.913258  |     72.75%  |  0.2s\n",
      "    89  |    0.650825  |  \u001b[32m  0.712116\u001b[0m  |     0.913930  |     72.73%  |  0.2s\n",
      "    90  |    0.650364  |  \u001b[32m  0.711113\u001b[0m  |     0.914572  |     72.77%  |  0.2s\n",
      "    91  |    0.649905  |  \u001b[32m  0.710136\u001b[0m  |     0.915183  |     72.81%  |  0.2s\n",
      "    92  |    0.649458  |  \u001b[32m  0.709164\u001b[0m  |     0.915808  |     72.83%  |  0.2s\n",
      "    93  |    0.648994  |  \u001b[32m  0.708193\u001b[0m  |     0.916409  |     72.85%  |  0.2s\n",
      "    94  |    0.648542  |  \u001b[32m  0.707251\u001b[0m  |     0.916989  |     72.86%  |  0.2s\n",
      "    95  |    0.648097  |  \u001b[32m  0.706332\u001b[0m  |     0.917554  |     72.85%  |  0.2s\n",
      "    96  |    0.647667  |  \u001b[32m  0.705424\u001b[0m  |     0.918125  |     72.90%  |  0.2s\n",
      "    97  |    0.647234  |  \u001b[32m  0.704522\u001b[0m  |     0.918685  |     72.92%  |  0.2s\n",
      "    98  |    0.646800  |  \u001b[32m  0.703612\u001b[0m  |     0.919257  |     72.97%  |  0.2s\n",
      "    99  |    0.646347  |  \u001b[32m  0.702733\u001b[0m  |     0.919762  |     73.02%  |  0.2s\n",
      "   100  |    0.645916  |  \u001b[32m  0.701903\u001b[0m  |     0.920235  |     73.03%  |  0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=<function matrix at 0x108be4ed8>,\n",
       "     batch_iterator_test=<nolearn.lasagne.BatchIterator object at 0x109a53410>,\n",
       "     batch_iterator_train=<nolearn.lasagne.BatchIterator object at 0x109a533d0>,\n",
       "     eval_size=0.2, hidden_num_units=128, input_shape=(None, 93),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('hidden', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=100, more_params={},\n",
       "     objective=<class 'lasagne.objectives.Objective'>,\n",
       "     objective_loss_function=<function categorical_crossentropy at 0x108dca488>,\n",
       "     on_epoch_finished=(), on_training_finished=(),\n",
       "     output_nonlinearity=<function softmax at 0x105fa4140>,\n",
       "     output_num_units=9, regression=False,\n",
       "     update=<function nesterov_momentum at 0x1097ca500>,\n",
       "     update_learning_rate=0.0001, use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.fit(X, y.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = load.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = net1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.19579721e-05,   7.58083257e-02,   4.54866027e-01, ...,\n",
       "          1.77164021e-02,   8.71776649e-06,   2.05714055e-05],\n",
       "       [  2.99845573e-03,   3.78092073e-04,   8.47790796e-05, ...,\n",
       "          1.18507158e-04,   4.08724243e-01,   1.73258540e-03],\n",
       "       [  2.24824154e-07,   8.04547203e-08,   8.60460097e-09, ...,\n",
       "          8.05620728e-06,   3.35199202e-05,   3.21060934e-06],\n",
       "       ..., \n",
       "       [  2.09205920e-07,   5.60069365e-02,   7.51657125e-01, ...,\n",
       "          3.16162849e-03,   5.09827752e-06,   4.47464172e-07],\n",
       "       [  4.98719393e-05,   2.99525205e-01,   3.68194208e-01, ...,\n",
       "          1.78026568e-03,   1.50806001e-04,   1.76497936e-04],\n",
       "       [  1.47759324e-03,   2.30405569e-01,   3.73946218e-01, ...,\n",
       "          1.83928706e-01,   9.73016344e-04,   1.63789204e-03]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load.gen_submission('lasagne_h1_100ep', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
